03/16/17 13:08:00 ******************************************************
03/16/17 13:08:00 ** condor_scheduniv_exec.75.0 (CONDOR_DAGMAN) STARTING UP
03/16/17 13:08:00 ** /usr/bin/condor_dagman
03/16/17 13:08:00 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
03/16/17 13:08:00 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
03/16/17 13:08:00 ** $CondorVersion: 8.4.2 Feb 22 2016 BuildID: Debian-8.4.2~dfsg.1-1build1 Debian-8.4.2~dfsg.1-1build1 $
03/16/17 13:08:00 ** $CondorPlatform: X86_64-Ubuntu_ $
03/16/17 13:08:00 ** PID = 2488980
03/16/17 13:08:00 ** Log last touched time unavailable (No such file or directory)
03/16/17 13:08:00 ******************************************************
03/16/17 13:08:00 Using config source: /etc/condor/condor_config
03/16/17 13:08:00 Using local config sources: 
03/16/17 13:08:00    /etc/condor/config.d/00debconf
03/16/17 13:08:00    /etc/condor/condor_config.local
03/16/17 13:08:00 config Macros = 70, Sorted = 70, StringBytes = 2050, TablesBytes = 2576
03/16/17 13:08:00 CLASSAD_CACHING is ENABLED
03/16/17 13:08:00 Daemon Log is logging: D_ALWAYS D_ERROR
03/16/17 13:08:00 DaemonCore: No command port requested.
03/16/17 13:08:00 DAGMAN_USE_STRICT setting: 1
03/16/17 13:08:00 DAGMAN_VERBOSITY setting: 3
03/16/17 13:08:00 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
03/16/17 13:08:00 DAGMAN_DEBUG_CACHE_ENABLE setting: False
03/16/17 13:08:00 DAGMAN_SUBMIT_DELAY setting: 0
03/16/17 13:08:00 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
03/16/17 13:08:00 DAGMAN_STARTUP_CYCLE_DETECT setting: False
03/16/17 13:08:00 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
03/16/17 13:08:00 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
03/16/17 13:08:00 DAGMAN_DEFAULT_PRIORITY setting: 0
03/16/17 13:08:00 DAGMAN_SUPPRESS_NOTIFICATION setting: True
03/16/17 13:08:00 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
03/16/17 13:08:00 DAGMAN_RETRY_SUBMIT_FIRST setting: True
03/16/17 13:08:00 DAGMAN_RETRY_NODE_FIRST setting: False
03/16/17 13:08:00 DAGMAN_MAX_JOBS_IDLE setting: 1000
03/16/17 13:08:00 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
03/16/17 13:08:00 DAGMAN_MAX_PRE_SCRIPTS setting: 20
03/16/17 13:08:00 DAGMAN_MAX_POST_SCRIPTS setting: 20
03/16/17 13:08:00 DAGMAN_ALLOW_LOG_ERROR setting: False
03/16/17 13:08:00 DAGMAN_MUNGE_NODE_NAMES setting: True
03/16/17 13:08:00 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
03/16/17 13:08:00 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
03/16/17 13:08:00 DAGMAN_ALWAYS_RUN_POST setting: True
03/16/17 13:08:00 DAGMAN_ABORT_DUPLICATES setting: True
03/16/17 13:08:00 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
03/16/17 13:08:00 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
03/16/17 13:08:00 DAGMAN_AUTO_RESCUE setting: True
03/16/17 13:08:00 DAGMAN_MAX_RESCUE_NUM setting: 100
03/16/17 13:08:00 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
03/16/17 13:08:00 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
03/16/17 13:08:00 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
03/16/17 13:08:00 DAGMAN_MAX_JOB_HOLDS setting: 100
03/16/17 13:08:00 DAGMAN_HOLD_CLAIM_TIME setting: 20
03/16/17 13:08:00 ALL_DEBUG setting: 
03/16/17 13:08:00 DAGMAN_DEBUG setting: 
03/16/17 13:08:00 DAGMAN_SUPPRESS_JOB_LOGS setting: False
03/16/17 13:08:00 argv[0] == "condor_scheduniv_exec.75.0"
03/16/17 13:08:00 argv[1] == "-Lockfile"
03/16/17 13:08:00 argv[2] == "process-0.dag.lock"
03/16/17 13:08:00 argv[3] == "-AutoRescue"
03/16/17 13:08:00 argv[4] == "1"
03/16/17 13:08:00 argv[5] == "-DoRescueFrom"
03/16/17 13:08:00 argv[6] == "0"
03/16/17 13:08:00 argv[7] == "-Dag"
03/16/17 13:08:00 argv[8] == "process-0.dag"
03/16/17 13:08:00 argv[9] == "-MaxPost"
03/16/17 13:08:00 argv[10] == "20"
03/16/17 13:08:00 argv[11] == "-Suppress_notification"
03/16/17 13:08:00 argv[12] == "-CsdVersion"
03/16/17 13:08:00 argv[13] == "$CondorVersion: 8.4.2 Feb 22 2016 BuildID: Debian-8.4.2~dfsg.1-1build1 Debian-8.4.2~dfsg.1-1build1 $"
03/16/17 13:08:00 argv[14] == "-Dagman"
03/16/17 13:08:00 argv[15] == "/usr/bin/condor_dagman"
03/16/17 13:08:00 Warning: failed to get attribute DAGNodeName
03/16/17 13:08:00 Ignoring value of DAGMAN_LOG_ON_NFS_IS_ERROR because ENABLE_USERLOG_LOCKING and CREATE_LOCKS_ON_LOCAL_DISK are true.
03/16/17 13:08:00 Default node log file is: </u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log>
03/16/17 13:08:00 DAG Lockfile will be written to process-0.dag.lock
03/16/17 13:08:00 DAG Input file is process-0.dag
03/16/17 13:08:00 Parsing 1 dagfiles
03/16/17 13:08:00 Parsing process-0.dag ...
03/16/17 13:08:00 Warning:  no value for submit_hostname in braindump file
03/16/17 13:08:00 Warning: category registration has no throttle value set
03/16/17 13:08:00 Warning: category stage-out has no throttle value set
03/16/17 13:08:00 Dag contains 5 total jobs
03/16/17 13:08:00 Sleeping for 3 seconds to ensure ProcessId uniqueness
03/16/17 13:08:03 Bootstrapping...
03/16/17 13:08:03 Number of pre-completed nodes: 0
03/16/17 13:08:03 MultiLogFiles: truncating log file /u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log
03/16/17 13:08:03 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:03 Of 5 nodes total:
03/16/17 13:08:03  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:03   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:03     0       0        0       0       1          4        0
03/16/17 13:08:03 0 job proc(s) currently held
03/16/17 13:08:03 Registering condor_event_timer...
03/16/17 13:08:04 Submitting Condor Node create_dir_process_0_local job(s)...
03/16/17 13:08:04 Adding a DAGMan workflow log /u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log
03/16/17 13:08:04 Masking the events recorded in the DAGMAN workflow log
03/16/17 13:08:04 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
03/16/17 13:08:04 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'create_dir_process_0_local -a +DAGManJobId' '=' '75 -a DAGManJobId' '=' '75 -a submit_event_notes' '=' 'DAG' 'Node:' 'create_dir_process_0_local -a dagman_log' '=' '/u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/create_dir_process_0_local.sub
03/16/17 13:08:04 From submit: Submitting job(s).
03/16/17 13:08:04 From submit: 1 job(s) submitted to cluster 76.
03/16/17 13:08:04 	assigned Condor ID (76.0.0)
03/16/17 13:08:04 Just submitted 1 job this cycle...
03/16/17 13:08:04 Currently monitoring 1 Condor log file(s)
03/16/17 13:08:04 Reassigning the id of job create_dir_process_0_local from (76.0.0) to (76.0.0)
03/16/17 13:08:04 Event: ULOG_SUBMIT for Condor Node create_dir_process_0_local (76.0.0)
03/16/17 13:08:04 Number of idle job procs: 1
03/16/17 13:08:04 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:04 Of 5 nodes total:
03/16/17 13:08:04  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:04   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:04     0       0        1       0       0          4        0
03/16/17 13:08:04 0 job proc(s) currently held
03/16/17 13:08:09 Currently monitoring 1 Condor log file(s)
03/16/17 13:08:09 Event: ULOG_EXECUTE for Condor Node create_dir_process_0_local (76.0.0)
03/16/17 13:08:09 Number of idle job procs: 0
03/16/17 13:08:09 Event: ULOG_JOB_TERMINATED for Condor Node create_dir_process_0_local (76.0.0)
03/16/17 13:08:09 Number of idle job procs: 0
03/16/17 13:08:09 Node create_dir_process_0_local job proc (76.0.0) completed successfully.
03/16/17 13:08:09 Node create_dir_process_0_local job completed
03/16/17 13:08:09 Running POST script of Node create_dir_process_0_local...
03/16/17 13:08:09 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
03/16/17 13:08:09 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:09 Of 5 nodes total:
03/16/17 13:08:09  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:09   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:09     0       0        0       1       0          4        0
03/16/17 13:08:09 0 job proc(s) currently held
03/16/17 13:08:09 Initializing user log writer for /u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log, (76.0.0)
03/16/17 13:08:14 Currently monitoring 1 Condor log file(s)
03/16/17 13:08:14 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node create_dir_process_0_local (76.0.0)
03/16/17 13:08:14 POST Script of Node create_dir_process_0_local completed successfully.
03/16/17 13:08:14 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:14 Of 5 nodes total:
03/16/17 13:08:14  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:14   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:14     1       0        0       0       1          3        0
03/16/17 13:08:14 0 job proc(s) currently held
03/16/17 13:08:19 Submitting Condor Node prms_ID0000001 job(s)...
03/16/17 13:08:19 Adding a DAGMan workflow log /u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log
03/16/17 13:08:19 Masking the events recorded in the DAGMAN workflow log
03/16/17 13:08:19 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
03/16/17 13:08:19 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'prms_ID0000001 -a +DAGManJobId' '=' '75 -a DAGManJobId' '=' '75 -a submit_event_notes' '=' 'DAG' 'Node:' 'prms_ID0000001 -a dagman_log' '=' '/u/obidele/PERF/PROJ/prms4.0.2_src/projects/sagehen/submit/obidele/pegasus/process/run0012/./process-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_process_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/prms_ID0000001.sub
03/16/17 13:08:19 From submit: Submitting job(s).
03/16/17 13:08:19 From submit: 1 job(s) submitted to cluster 77.
03/16/17 13:08:19 	assigned Condor ID (77.0.0)
03/16/17 13:08:19 Just submitted 1 job this cycle...
03/16/17 13:08:19 Currently monitoring 1 Condor log file(s)
03/16/17 13:08:19 Reassigning the id of job prms_ID0000001 from (77.0.0) to (77.0.0)
03/16/17 13:08:19 Event: ULOG_SUBMIT for Condor Node prms_ID0000001 (77.0.0)
03/16/17 13:08:19 Number of idle job procs: 1
03/16/17 13:08:19 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:19 Of 5 nodes total:
03/16/17 13:08:19  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:19   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:19     1       0        1       0       0          3        0
03/16/17 13:08:19 0 job proc(s) currently held
03/16/17 13:08:24 Currently monitoring 1 Condor log file(s)
03/16/17 13:08:24 Event: ULOG_EXECUTE for Condor Node prms_ID0000001 (77.0.0)
03/16/17 13:08:24 Number of idle job procs: 0
03/16/17 13:08:24 Event: ULOG_SHADOW_EXCEPTION for Condor Node prms_ID0000001 (77.0.0)
03/16/17 13:08:24 Number of idle job procs: 1
03/16/17 13:08:24 Event: ULOG_JOB_HELD for Condor Node prms_ID0000001 (77.0.0)
03/16/17 13:08:24   Hold reason: Error from slot1@dewey.cs.pdx.edu: STARTER at 127.0.0.1 failed to send file(s) to <127.0.0.1:38985>: error reading from /var/lib/condor/execute/dir_2489057/sagehen.control: (errno 2) No such file or directory; SHADOW failed to receive file(s) from <127.0.0.1:56991>
03/16/17 13:08:24 Number of idle job procs: 1
03/16/17 13:08:24 DAG status: 0 (DAG_STATUS_OK)
03/16/17 13:08:24 Of 5 nodes total:
03/16/17 13:08:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:08:24   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:08:24     1       0        1       0       0          3        0
03/16/17 13:08:24 1 job proc(s) currently held
03/16/17 13:16:10 DAG is halted because halt file process-0.dag.halt exists
03/16/17 13:16:15 DAG is halted because halt file process-0.dag.halt exists
03/16/17 13:16:16 Received SIGUSR1
03/16/17 13:16:16 Aborting DAG...
03/16/17 13:16:16 Writing Rescue DAG to process-0.dag.rescue001...
03/16/17 13:16:16 Removing submitted jobs...
03/16/17 13:16:16 Note: 0 total job deferrals because of -MaxJobs limit (0)
03/16/17 13:16:16 Note: 0 total job deferrals because of -MaxIdle limit (1000)
03/16/17 13:16:16 Note: 0 total job deferrals because of node category throttles
03/16/17 13:16:16 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
03/16/17 13:16:16 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
03/16/17 13:16:16 DAG status: 4 (DAG_STATUS_RM)
03/16/17 13:16:16 Of 5 nodes total:
03/16/17 13:16:16  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/16/17 13:16:16   ===     ===      ===     ===     ===        ===      ===
03/16/17 13:16:16     1       0        1       0       0          3        0
03/16/17 13:16:16 1 job proc(s) currently held
03/16/17 13:16:17 Wrote metrics file process-0.dag.metrics.
03/16/17 13:16:17 Reporting metrics to Pegasus metrics server(s); output is in process-0.dag.metrics.out.
03/16/17 13:16:17 Running command </usr/lib/condor/libexec/condor_dagman_metrics_reporter -f process-0.dag.metrics -s -t 100>
03/16/17 13:16:17 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
03/16/17 13:16:17 **** condor_scheduniv_exec.75.0 (condor_DAGMAN) pid 2488980 EXITING WITH STATUS 2
